{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f509fc1215384f94985d7963967ebaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46c05e1ddeb34859a419ebe29842610a",
              "IPY_MODEL_918cddd739704e3a9ce7473e21876f4e",
              "IPY_MODEL_043039f800a14b58aea30892fe69a8f5"
            ],
            "layout": "IPY_MODEL_1b53857724904540889c579027aff63c"
          }
        },
        "46c05e1ddeb34859a419ebe29842610a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1016b18960a848e9865b39cab19e961c",
            "placeholder": "​",
            "style": "IPY_MODEL_80210deab2184bdc8f6a574cb5684834",
            "value": "100%"
          }
        },
        "918cddd739704e3a9ce7473e21876f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3f56aca971d440f8cff6b9e1da6e9db",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b01bac169f84ce2aa43ec8e917764e0",
            "value": 100
          }
        },
        "043039f800a14b58aea30892fe69a8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c5f09196274ecc8b985bd0d106240d",
            "placeholder": "​",
            "style": "IPY_MODEL_c15554fd86e2420fb5ef8d789f8540c0",
            "value": " 100/100 [elapsed: 24:17 remaining: 00:00]"
          }
        },
        "1b53857724904540889c579027aff63c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1016b18960a848e9865b39cab19e961c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80210deab2184bdc8f6a574cb5684834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f56aca971d440f8cff6b9e1da6e9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b01bac169f84ce2aa43ec8e917764e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50c5f09196274ecc8b985bd0d106240d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15554fd86e2420fb5ef8d789f8540c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Highly accurate protein structure prediction with AlphaFold\n",
        "\n",
        "-   **Net ID**: ks7406\n",
        "-   **Name**: Khushi Sharma"
      ],
      "metadata": {
        "id": "JVRYtWLgkXH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jumper, J., Evans, R., Pritzel, A. et al. Highly accurate protein structure prediction with AlphaFold. Nature 596, 583–589 (2021).[1]"
      ],
      "metadata": {
        "id": "8Ib9nxwmslEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "### Introduction: What task is this technique for?\n",
        "\n",
        "The protein folding problem is a long standing question about how a protein's amino acid sequence - i.e, the building polypeptide blocks of a protein - folds and dictates its 3-dimensional structure, which subsequently determines the functionality of the protein [2]. Experimentally, figuring out the structure of a protein involves expensive methods (like X-Ray crystallography or NMR spectrascopy) that can take up to a full PhD to give a conclusive result [3]. Computationally, however, researchers using traditional algorithmic methods faced a roadblock described by the Levinthal's paradox - an algorithmic search for the most stable configuration could take  time tending to infinity, while protein folding in reality happens very quickly [2]. That is, until researchers started using the burgeoning field of Machine Learning to dig at the problem.\n",
        "\n",
        "This paper provides the description of the first computational method that can figure out the structure of a protein with atomic accuracy. In particular, it details the working of the AlphaFold deep learning model developed by DeepMind that was able to achieve previously unprecented accuracy levels in the binennial protein structure prediction experiment called Critical Assessment of Structure Prediction in 2020. Please note that by AlphaFold we are referring to the AlphaFold2 model throughout this report. The first AlphaFold model will be referred to as AlphaFold1 wherever necessary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fgp9nhU5kbLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How exactly does this technique work?\n",
        "#### **On a High Level**\n",
        "\n",
        "![Model Overview](https://drive.google.com/uc?export=view&id=1epkoyvieI8q5GD9Ob4-uieQn8Qq2Ud2I)\n",
        "Fig 1. Model architecture (Fig 1.e from [1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pkg5N2sGcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlphaFold, the end-to-end neural network, is based on both evolutionary and physical constraints of protein structures (along with geometric constraints). Some salient features of the model and its training methodology are as follows:\n",
        "* *Based on both multiple sequence alignments (MSAs) and pairwise\n",
        "features:* Earlier, computational methods had focussed either on simulating the physical interactions between the atoms in the protein or, more recently, the evolutionary history. While the former has been challenging because of computational intractability of molecular simulation (among other reasons), the evolutionary program - which includes bioinformatics analysis of the evolutionary history of proteins, homology to solved structures and pairwise evolutionary correlations - has been a promising path. AlphaFold utilizes both these approaches\n",
        "* *New output representation associated loss that enable\n",
        "accurate end-to-end structure prediction*: In AlphaFold1 model, the neural network produced a distance map which estimated a probability distribution for how close the residues might be. This was combined with energy calculations at a later stage to output the 3D structure. In contrast, AlphaFold is able to take in an amino acid and directly predict the 3D structure.\n",
        "* *New equivariant attention architecture:* While AlphaFold1 and other deep learning attempts at the time utilized convolutional networks, AlphaFold uses attention networks, which are explained in a later section.\n",
        "* *Use of intermediate losses to achieve iterative refinement\n",
        "of predictions:* The model is refined iteratively using the whole network instead of in chunks, a concept known as recycling.\n",
        "\n",
        "\n",
        "The model is made of two main stages - the Evoformer and the Structure Module. Given the input of amino acid sequence and its aligned sequences of homologues, the evoformer contains several attention-based and non-attention-based components dealing with MSA and pairwise features. The structure module introduces an explicit 3D structure in the form of a rotation and translation and refines the precise atomic details of the backbone and side-chain atoms. Both these stages employ a special mechanism called \"attention\" that play a winning role in the accuracy of AlphaFold.\n",
        "\n",
        "**Brief Explanation of Attention Networks**\n",
        "\n",
        "Attention networks, which came into the forefront of cutting-edge deep learning in form of transformers, are an improvement on Recurrent Neural Networks [5]. The basic idea is as follows: it allows the network to learn to focus its attention and assign importance to different sections of the input based on similarity [6]. While RNNs also process the input sectionally, it's done in a sequential manner which inadvertenly favours the most recent section, biasing the model [5]. Attention networks can establish far away connections if the input embeddings are similar (similar to fully-connected networks), which is also in contrast to convolutional networks which operate on spatially close subsections of the input [6].\n",
        "\n"
      ],
      "metadata": {
        "id": "IBgAFAMPnRbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**The Evoformer**\n",
        "\n",
        "\n",
        "![Fig 2. Evoformer](https://drive.google.com/uc?export=view&id=1DoRrHOB_I7Ktr6E9rtAiDwpFd1KUwhFz)\n",
        "Fig 2. Evoformer block (Fig 3.a from [1])\n",
        "\n",
        "There are two inputs to the Evoformer block that get refined as the block is run. First is the the pair representation, which is achieved from pairing the residues (which are individual amino acids) of the input amino acid sequence. The second is the MSA alignment, to generate which the amino acid sequence is compared with historical sequences in order to select sequences in which those residues also appear. The Pair representation is a matrix of size N_res * N_res (where N_res = number of residues in the amino acid sequence), and the MSA representation is a matrix of size N_res * N_seq (where N_seq is the number of similar sequences). A number of operations are applied on both of these matrices in series - which we will collectively call a block. These blocks are repeated 48 times to get to the final MSA and pair representations.\n",
        "\n",
        "The updates to the two matrices are interrelated, allowing a continuous mixing of information between the two. The MSA representation updates the pair matrix through an outer product mean summed over the N_seq dimension.\n",
        "The pair representation is further updated using the concept of triangle inequality on distances. On the basis of this intuition, we\n",
        "arrange the update operations on the pair representation in terms of\n",
        "triangles of edges involving three different nodes. This traingle updation is also done in two patterns - attention update and multiplicative update.\n",
        "The idea to apply both of these patterns was novel and led to more accurate updates. As for the updates to the MSA representation, additional logits from the pair matrix are added as a bias while applying attention to the MSA."
      ],
      "metadata": {
        "id": "7CRLVPE72RJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Structure Module**\n",
        "\n",
        "![Fig 3. Structure Module](https://drive.google.com/uc?export=view&id=1OztE5yzXldtno8g5vgbr25hlgqI6Ex7N)\n",
        "Fig 3. Structure Module (Fig 3.d from [1])\n",
        "\n",
        "The structure module takes the pair representation and the first row of the MSA representation (the original sequence row) as input. The\n",
        "3D backbone structure is represented as N_res independent rotations\n",
        "and translations, each with respect to the global frame. These rotations and translations — called the backbone frames that represent the N-Cα-C atoms — focus on the the orientation of the protein backbone. As a result, while the location of the side chain of each residue is highly\n",
        "constrained, the geometry of the peptide bonds inside each residue is completely unconstrained. While this means that the chain constraint is violates during the application of the structure module, it's becomes an advantage because it allows local refinement of all parts of the chain without having to solve the complex details every time. Exact enforcement of peptide bond geometry is only satisfied later via fine-tuning\n",
        "by a violation loss term and in the post-prediction relaxation of the structure by gradient descent.\n",
        "\n",
        "The backbone (or residue gas) representation is updated iteratively in two stages - a geometry-aware attention operation (called Invariant Point Attention (IPA)), and an equivariant update operation. IPA updates an N_res set of neural activations without changing the 3D positions and the update operation is performed on the residue gas using the updated activations. Side-chain χ angles and the final, per-residue accuracy of the structure (pLDDT) are predicted with small per-residue networks on the final activations at the end of the network.\n",
        "\n",
        "We compare the predicted atom positions to the true positions under many different alignments to compute the final loss - frame-aligned point error (FAPE). The resulting Nframes × Natoms distances are penalized with a clamped L1 loss. This is a form of regularization that forces atoms to be correct relative to the local frame of each residue.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ff0cCQTUteRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**\n",
        "1. First, the network is trained using labelled data from the Protein Data Bank (PDB), which has experimentally determined structures.\n",
        "2. We use this trained network to predict the structure of\n",
        "around 350,000 sequences from Uniclust3036. We take a high-confidence subset from these structures to facilitate further training.\n",
        "3. Now we once again train the network from scratch, but this time using a combination of PDB data and the structures generated above (which is, in a way, unlabelled data because we cannot confirm those structures). This procedure is called Self-Distillation.\n",
        "\n",
        "Another special feature of training is random masking out or mutation of individual residues within the MSA and having a Bidirectional Encoder Representations from Transformers (BERT)-style objective to predict the masked elements of the MSA sequences. This idea is similar to the concept of drop-out and encourgaes the network to learn without hardcoding\n",
        "a particular statistics into the features.\n"
      ],
      "metadata": {
        "id": "YZo1Fkmn4U9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####What other techniques are there for similar problems? What is special about this technique, compared to the others?\n",
        "\n",
        "What makes this technique special is the high accuracy especially in cases where homologous templates of sequences aren't known. AlphaFold structures had a median backbone accuracy 0.85–1.16 Å and all-atom accuracy of 1.2–1.6 Å, whereas the next best performing method is at 2.7–4.0 Å and 3.1–4.2 Å for backbone and all-atom accuracy respectively (width of a carbon atom = 1.4 Å).\n",
        "\n",
        "A combination of the following ideas led to this success:\n",
        "*   self-distillation training\n",
        "*   having a template stack\n",
        "*   performing attention on individual MSA sequences\n",
        "*   the triangle inductive bias while update pair representation\n",
        "*   recycling\n",
        "*   invariant point attention while predicting backbone frames\n",
        "*   end-to-end training\n",
        "*   using BERT-style loss function after masking some MSA residues\n",
        "\n",
        "We can see from the graph below that each of these ideas contributed to the accuracy. This is the result of an ablation study, which investigates the performance of a model by removing certain components to understand the contribution of individual component.[7]\n",
        "![Fig 4.  Ablation results](https://drive.google.com/uc?export=view&id=171RukV1qb3AmCxrKxHMZK21JEHZlb2vn)\n",
        "Fig 4. Ablation results (Fig 4.a from [1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z2TiM3-QnNId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What kind of problems/data would it not perform well on? Why?\n",
        "AlphaFold's accuracy is limited in cases where N_seq is less than around 30 sequences. Additionally, it performs worse for proteins that have few intra-chain or homotypic contacts in comparison to the number of heterotypic contacts. Thus, in further studies it has been observed that in nearly 1/3 of cases the accuracy of the AlphaFold2 model was below the level of experimental accuracy [8]."
      ],
      "metadata": {
        "id": "S_66v8434fWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Claim\n",
        "\n",
        "The main claim:\n",
        "- AlphaFold structures had a median backbone accuracy of 0.96 Å r.m.s.d.95 and all-atom accuracy of 1.5 Å r.m.s.d.95. This is computed by taking an average of the predicted aligned error of each atom in the protein after aligning the predicted and experimental structures.\n",
        "\n",
        "Other claims:\n",
        "AlphaFold secured a GDT_TS score of 92.4 overall across all targets in the 14th CASP assessment. For the very hardest protein targets, those in the most challenging free-modelling category, AlphaFold achieves a median score of 87.0 GDT. GDT (Global Distance Test) is the main metric used by CASP to measure the accuracy of predictions and it ranges from 0-100.\n",
        "The GDT score is teh fraction of alpha carbon atoms of amino acidsthat fall within a defined distance cutoff of their position in the experimental structure, after superimposing it with the predicted structure. GDT_TS total score in CASP is the average result of cutoffs at 1, 2, 4, and 8 Å.\n",
        "\n",
        "\n",
        "Evidence:\n",
        "![Fig 5.  Ablation results](https://drive.google.com/uc?export=view&id=1z0jnvAgCvcq6YBJCUG9pDBeI0Ax3BX30)\n",
        "Fig 5. Accuracy (Fig 1.a from [1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMu8N69WxwdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Independent Validation**\n"
      ],
      "metadata": {
        "id": "7kuFcRSsDIzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code\n",
        "\n",
        "Source of the code: https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "JDL_44PixsJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables before running any other code.\n",
        "import os\n",
        "os.environ['TF_FORCE_UNIFIED_MEMORY'] = '1'\n",
        "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '4.0'\n",
        "\n",
        "#@title 1. Install third-party software\n",
        "\n",
        "#@markdown Please execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left to download and import third-party software\n",
        "#@markdown in this Colab notebook. (See the [acknowledgements](https://github.com/deepmind/alphafold/#acknowledgements) in our readme.)\n",
        "\n",
        "#@markdown **Note**: This installs the software on the Colab\n",
        "#@markdown notebook in the cloud and not on your computer.\n",
        "\n",
        "from IPython.utils import io\n",
        "import os\n",
        "import subprocess\n",
        "import tqdm.notebook\n",
        "\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "\n",
        "try:\n",
        "  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "    with io.capture_output() as captured:\n",
        "      # Uninstall default Colab version of TF.\n",
        "      %shell pip uninstall -y tensorflow\n",
        "\n",
        "      %shell sudo apt install --quiet --yes hmmer\n",
        "      pbar.update(6)\n",
        "\n",
        "      # Install py3dmol.\n",
        "      %shell pip install py3dmol\n",
        "      pbar.update(2)\n",
        "\n",
        "      # Install OpenMM and pdbfixer.\n",
        "      %shell rm -rf /opt/conda\n",
        "      %shell wget -q -P /tmp \\\n",
        "        https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
        "          && bash /tmp/Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda \\\n",
        "          && rm /tmp/Miniconda3-latest-Linux-x86_64.sh\n",
        "      pbar.update(9)\n",
        "\n",
        "      PATH=%env PATH\n",
        "      %env PATH=/opt/conda/bin:{PATH}\n",
        "      %shell conda install -qy conda==23.5.2 \\\n",
        "          && conda install -qy -c conda-forge \\\n",
        "            python=3.10 \\\n",
        "            openmm=7.7.0 \\\n",
        "            pdbfixer\n",
        "      pbar.update(80)\n",
        "\n",
        "      # Create a ramdisk to store a database chunk to make Jackhmmer run fast.\n",
        "      %shell sudo mkdir -m 777 --parents /tmp/ramdisk\n",
        "      %shell sudo mount -t tmpfs -o size=9G ramdisk /tmp/ramdisk\n",
        "      pbar.update(2)\n",
        "\n",
        "      %shell wget -q -P /content \\\n",
        "        https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
        "      pbar.update(1)\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "\n",
        "executed_cells = set([1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f509fc1215384f94985d7963967ebaeb",
            "46c05e1ddeb34859a419ebe29842610a",
            "918cddd739704e3a9ce7473e21876f4e",
            "043039f800a14b58aea30892fe69a8f5",
            "1b53857724904540889c579027aff63c",
            "1016b18960a848e9865b39cab19e961c",
            "80210deab2184bdc8f6a574cb5684834",
            "f3f56aca971d440f8cff6b9e1da6e9db",
            "3b01bac169f84ce2aa43ec8e917764e0",
            "50c5f09196274ecc8b985bd0d106240d",
            "c15554fd86e2420fb5ef8d789f8540c0"
          ]
        },
        "id": "8YIiUQ1xCBnM",
        "outputId": "33742542-94d5-4cb5-fb75-2ec02881b239"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [elapsed: 00:00 remaining: ?]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f509fc1215384f94985d7963967ebaeb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download AlphaFold\n",
        "\n",
        "#@markdown Please execute this cell by pressing the *Play* button on\n",
        "#@markdown the left.\n",
        "\n",
        "GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
        "SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_colab_2022-12-06.tar'\n",
        "PARAMS_DIR = './alphafold/data/params'\n",
        "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n",
        "\n",
        "try:\n",
        "  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "    with io.capture_output() as captured:\n",
        "      %shell rm -rf alphafold\n",
        "      %shell git clone --branch main {GIT_REPO} alphafold\n",
        "      pbar.update(8)\n",
        "      # Install the required versions of all dependencies.\n",
        "      %shell pip3 install -r ./alphafold/requirements.txt\n",
        "      # Run setup.py to install only AlphaFold.\n",
        "      %shell pip3 install --no-dependencies ./alphafold\n",
        "      %shell pip3 install pyopenssl==22.0.0\n",
        "      pbar.update(10)\n",
        "\n",
        "      # Make sure stereo_chemical_props.txt is in all locations where it could be searched for.\n",
        "      %shell mkdir -p /content/alphafold/alphafold/common\n",
        "      %shell cp -f /content/stereo_chemical_props.txt /content/alphafold/alphafold/common\n",
        "      %shell mkdir -p /opt/conda/lib/python3.10/site-packages/alphafold/common/\n",
        "      %shell cp -f /content/stereo_chemical_props.txt /opt/conda/lib/python3.10/site-packages/alphafold/common/\n",
        "\n",
        "      # Load parameters\n",
        "      %shell mkdir --parents \"{PARAMS_DIR}\"\n",
        "      %shell wget -O \"{PARAMS_PATH}\" \"{SOURCE_URL}\"\n",
        "      pbar.update(27)\n",
        "\n",
        "      %shell tar --extract --verbose --file=\"{PARAMS_PATH}\" \\\n",
        "        --directory=\"{PARAMS_DIR}\" --preserve-permissions\n",
        "      %shell rm \"{PARAMS_PATH}\"\n",
        "      pbar.update(55)\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "\n",
        "import jax\n",
        "if jax.local_devices()[0].platform == 'tpu':\n",
        "  raise RuntimeError('Colab TPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
        "elif jax.local_devices()[0].platform == 'cpu':\n",
        "  raise RuntimeError('Colab CPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
        "else:\n",
        "  print(f'Running with {jax.local_devices()[0].device_kind} GPU')\n",
        "\n",
        "# Make sure everything we need is on the path.\n",
        "import sys\n",
        "sys.path.append('/opt/conda/lib/python3.10/site-packages')\n",
        "sys.path.append('/content/alphafold')\n",
        "\n",
        "executed_cells.add(2)"
      ],
      "metadata": {
        "id": "rfd-XyXFCgo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Enter the amino acid sequence(s) to fold ⬇️\n",
        "#@markdown Enter the amino acid sequence(s) to fold:\n",
        "#@markdown * If you enter only a single sequence, the monomer model will be\n",
        "#@markdown used (unless you override this below).\n",
        "#@markdown * If you enter multiple sequences, the multimer model will be used.\n",
        "\n",
        "from alphafold.notebooks import notebook_utils\n",
        "# Track cell execution to ensure correct order.\n",
        "notebook_utils.check_cell_execution_order(executed_cells, 3)\n",
        "\n",
        "import enum\n",
        "\n",
        "@enum.unique\n",
        "class ModelType(enum.Enum):\n",
        "  MONOMER = 0\n",
        "  MULTIMER = 1\n",
        "\n",
        "sequence_1 = 'MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH'  #@param {type:\"string\"}\n",
        "sequence_2 = ''  #@param {type:\"string\"}\n",
        "sequence_3 = ''  #@param {type:\"string\"}\n",
        "sequence_4 = ''  #@param {type:\"string\"}\n",
        "sequence_5 = ''  #@param {type:\"string\"}\n",
        "sequence_6 = ''  #@param {type:\"string\"}\n",
        "sequence_7 = ''  #@param {type:\"string\"}\n",
        "sequence_8 = ''  #@param {type:\"string\"}\n",
        "sequence_9 = ''  #@param {type:\"string\"}\n",
        "sequence_10 = ''  #@param {type:\"string\"}\n",
        "sequence_11 = ''  #@param {type:\"string\"}\n",
        "sequence_12 = ''  #@param {type:\"string\"}\n",
        "sequence_13 = ''  #@param {type:\"string\"}\n",
        "sequence_14 = ''  #@param {type:\"string\"}\n",
        "sequence_15 = ''  #@param {type:\"string\"}\n",
        "sequence_16 = ''  #@param {type:\"string\"}\n",
        "sequence_17 = ''  #@param {type:\"string\"}\n",
        "sequence_18 = ''  #@param {type:\"string\"}\n",
        "sequence_19 = ''  #@param {type:\"string\"}\n",
        "sequence_20 = ''  #@param {type:\"string\"}\n",
        "\n",
        "input_sequences = (\n",
        "    sequence_1, sequence_2, sequence_3, sequence_4, sequence_5,\n",
        "    sequence_6, sequence_7, sequence_8, sequence_9, sequence_10,\n",
        "    sequence_11, sequence_12, sequence_13, sequence_14, sequence_15,\n",
        "    sequence_16, sequence_17, sequence_18, sequence_19, sequence_20)\n",
        "\n",
        "MIN_PER_SEQUENCE_LENGTH = 16\n",
        "MAX_PER_SEQUENCE_LENGTH = 4000\n",
        "MAX_MONOMER_MODEL_LENGTH = 2500\n",
        "MAX_LENGTH = 4000\n",
        "MAX_VALIDATED_LENGTH = 3000\n",
        "\n",
        "#@markdown Select this checkbox to run the multimer model for a single sequence.\n",
        "#@markdown For proteins that are monomeric in their native form, or for very\n",
        "#@markdown large single chains you may get better accuracy and memory efficiency\n",
        "#@markdown by using the multimer model.\n",
        "#@markdown\n",
        "#@markdown\n",
        "#@markdown Due to improved memory efficiency the multimer model has a maximum\n",
        "#@markdown limit of 4000 residues, while the monomer model has a limit of 2500\n",
        "#@markdown residues.\n",
        "\n",
        "use_multimer_model_for_monomers = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Validate the input sequences.\n",
        "sequences = notebook_utils.clean_and_validate_input_sequences(\n",
        "    input_sequences=input_sequences,\n",
        "    min_sequence_length=MIN_PER_SEQUENCE_LENGTH,\n",
        "    max_sequence_length=MAX_PER_SEQUENCE_LENGTH)\n",
        "\n",
        "if len(sequences) == 1:\n",
        "  if use_multimer_model_for_monomers:\n",
        "    print('Using the multimer model for single-chain, as requested.')\n",
        "    model_type_to_use = ModelType.MULTIMER\n",
        "  else:\n",
        "    print('Using the single-chain model.')\n",
        "    model_type_to_use = ModelType.MONOMER\n",
        "else:\n",
        "  print(f'Using the multimer model with {len(sequences)} sequences.')\n",
        "  model_type_to_use = ModelType.MULTIMER\n",
        "\n",
        "# Check whether total length exceeds limit.\n",
        "total_sequence_length = sum([len(seq) for seq in sequences])\n",
        "if total_sequence_length > MAX_LENGTH:\n",
        "  raise ValueError('The total sequence length is too long: '\n",
        "                   f'{total_sequence_length}, while the maximum is '\n",
        "                   f'{MAX_LENGTH}.')\n",
        "\n",
        "# Check whether we exceed the monomer limit.\n",
        "if model_type_to_use == ModelType.MONOMER:\n",
        "  if len(sequences[0]) > MAX_MONOMER_MODEL_LENGTH:\n",
        "    raise ValueError(\n",
        "        f'Input sequence is too long: {len(sequences[0])} amino acids, while '\n",
        "        f'the maximum for the monomer model is {MAX_MONOMER_MODEL_LENGTH}. You may '\n",
        "        'be able to run this sequence with the multimer model by selecting the '\n",
        "        'use_multimer_model_for_monomers checkbox above.')\n",
        "\n",
        "if total_sequence_length > MAX_VALIDATED_LENGTH:\n",
        "  print('WARNING: The accuracy of the system has not been fully validated '\n",
        "        'above 3000 residues, and you may experience long running times or '\n",
        "        f'run out of memory. Total sequence length is {total_sequence_length} '\n",
        "        'residues.')\n",
        "\n",
        "executed_cells.add(3)"
      ],
      "metadata": {
        "id": "O350fIksCkj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Search against genetic databases\n",
        "\n",
        "#@markdown Once this cell has been executed, you will see\n",
        "#@markdown statistics about the multiple sequence alignment\n",
        "#@markdown (MSA) that will be used by AlphaFold. In particular,\n",
        "#@markdown you’ll see how well each residue is covered by similar\n",
        "#@markdown sequences in the MSA.\n",
        "\n",
        "# Track cell execution to ensure correct order\n",
        "notebook_utils.check_cell_execution_order(executed_cells, 4)\n",
        "\n",
        "# --- Python imports ---\n",
        "import collections\n",
        "import copy\n",
        "from concurrent import futures\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from urllib import request\n",
        "from google.colab import files\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import py3Dmol\n",
        "\n",
        "from alphafold.model import model\n",
        "from alphafold.model import config\n",
        "from alphafold.model import data\n",
        "\n",
        "from alphafold.data import feature_processing\n",
        "from alphafold.data import msa_pairing\n",
        "from alphafold.data import pipeline\n",
        "from alphafold.data import pipeline_multimer\n",
        "from alphafold.data.tools import jackhmmer\n",
        "\n",
        "from alphafold.common import confidence\n",
        "from alphafold.common import protein\n",
        "\n",
        "from alphafold.relax import relax\n",
        "from alphafold.relax import utils\n",
        "\n",
        "from IPython import display\n",
        "from ipywidgets import GridspecLayout\n",
        "from ipywidgets import Output\n",
        "\n",
        "# Color bands for visualizing plddt\n",
        "PLDDT_BANDS = [(0, 50, '#FF7D45'),\n",
        "               (50, 70, '#FFDB13'),\n",
        "               (70, 90, '#65CBF3'),\n",
        "               (90, 100, '#0053D6')]\n",
        "\n",
        "# --- Find the closest source ---\n",
        "test_url_pattern = 'https://storage.googleapis.com/alphafold-colab{:s}/latest/uniref90_2022_01.fasta.1'\n",
        "ex = futures.ThreadPoolExecutor(3)\n",
        "def fetch(source):\n",
        "  request.urlretrieve(test_url_pattern.format(source))\n",
        "  return source\n",
        "fs = [ex.submit(fetch, source) for source in ['', '-europe', '-asia']]\n",
        "source = None\n",
        "for f in futures.as_completed(fs):\n",
        "  source = f.result()\n",
        "  ex.shutdown()\n",
        "  break\n",
        "\n",
        "JACKHMMER_BINARY_PATH = '/usr/bin/jackhmmer'\n",
        "DB_ROOT_PATH = f'https://storage.googleapis.com/alphafold-colab{source}/latest/'\n",
        "# The z_value is the number of sequences in a database.\n",
        "MSA_DATABASES = [\n",
        "    {'db_name': 'uniref90',\n",
        "     'db_path': f'{DB_ROOT_PATH}uniref90_2022_01.fasta',\n",
        "     'num_streamed_chunks': 62,\n",
        "     'z_value': 144_113_457},\n",
        "    {'db_name': 'smallbfd',\n",
        "     'db_path': f'{DB_ROOT_PATH}bfd-first_non_consensus_sequences.fasta',\n",
        "     'num_streamed_chunks': 17,\n",
        "     'z_value': 65_984_053},\n",
        "    {'db_name': 'mgnify',\n",
        "     'db_path': f'{DB_ROOT_PATH}mgy_clusters_2022_05.fasta',\n",
        "     'num_streamed_chunks': 120,\n",
        "     'z_value': 623_796_864},\n",
        "]\n",
        "\n",
        "# Search UniProt and construct the all_seq features only for heteromers, not homomers.\n",
        "if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
        "  MSA_DATABASES.extend([\n",
        "      # Swiss-Prot and TrEMBL are concatenated together as UniProt.\n",
        "      {'db_name': 'uniprot',\n",
        "       'db_path': f'{DB_ROOT_PATH}uniprot_2021_04.fasta',\n",
        "       'num_streamed_chunks': 101,\n",
        "       'z_value': 225_013_025 + 565_928},\n",
        "  ])\n",
        "\n",
        "TOTAL_JACKHMMER_CHUNKS = sum([cfg['num_streamed_chunks'] for cfg in MSA_DATABASES])\n",
        "\n",
        "MAX_HITS = {\n",
        "    'uniref90': 10_000,\n",
        "    'smallbfd': 5_000,\n",
        "    'mgnify': 501,\n",
        "    'uniprot': 50_000,\n",
        "}\n",
        "\n",
        "\n",
        "def get_msa(sequences):\n",
        "  \"\"\"Searches for MSA for given sequences using chunked Jackhmmer search.\n",
        "\n",
        "  Args:\n",
        "    sequences: A list of sequences to search against all databases.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary mapping unique sequences to dicionaries mapping each database\n",
        "    to a list of  results, one for each chunk of the database.\n",
        "  \"\"\"\n",
        "  sequence_to_fasta_path = {}\n",
        "  # Deduplicate to not do redundant work for multiple copies of the same chain in homomers.\n",
        "  for sequence_index, sequence in enumerate(sorted(set(sequences)), 1):\n",
        "    fasta_path = f'target_{sequence_index:02d}.fasta'\n",
        "    with open(fasta_path, 'wt') as f:\n",
        "      f.write(f'>query\\n{sequence}')\n",
        "    sequence_to_fasta_path[sequence] = fasta_path\n",
        "\n",
        "  # Run the search against chunks of genetic databases (since the genetic\n",
        "  # databases don't fit in Colab disk).\n",
        "  raw_msa_results = {sequence: {} for sequence in sequence_to_fasta_path.keys()}\n",
        "  print('\\nGetting MSA for all sequences')\n",
        "  with tqdm.notebook.tqdm(total=TOTAL_JACKHMMER_CHUNKS, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "    def jackhmmer_chunk_callback(i):\n",
        "      pbar.update(n=1)\n",
        "\n",
        "    for db_config in MSA_DATABASES:\n",
        "      db_name = db_config['db_name']\n",
        "      pbar.set_description(f'Searching {db_name}')\n",
        "      jackhmmer_runner = jackhmmer.Jackhmmer(\n",
        "          binary_path=JACKHMMER_BINARY_PATH,\n",
        "          database_path=db_config['db_path'],\n",
        "          get_tblout=True,\n",
        "          num_streamed_chunks=db_config['num_streamed_chunks'],\n",
        "          streaming_callback=jackhmmer_chunk_callback,\n",
        "          z_value=db_config['z_value'])\n",
        "      # Query all unique sequences against each chunk of the database to prevent\n",
        "      # redunantly fetching each chunk for each unique sequence.\n",
        "      results = jackhmmer_runner.query_multiple(list(sequence_to_fasta_path.values()))\n",
        "      for sequence, result_for_sequence in zip(sequence_to_fasta_path.keys(), results):\n",
        "        raw_msa_results[sequence][db_name] = result_for_sequence\n",
        "\n",
        "  return raw_msa_results\n",
        "\n",
        "\n",
        "features_for_chain = {}\n",
        "raw_msa_results_for_sequence = get_msa(sequences)\n",
        "for sequence_index, sequence in enumerate(sequences, start=1):\n",
        "  raw_msa_results = copy.deepcopy(raw_msa_results_for_sequence[sequence])\n",
        "\n",
        "  # Extract the MSAs from the Stockholm files.\n",
        "  # NB: deduplication happens later in pipeline.make_msa_features.\n",
        "  single_chain_msas = []\n",
        "  uniprot_msa = None\n",
        "  for db_name, db_results in raw_msa_results.items():\n",
        "    merged_msa = notebook_utils.merge_chunked_msa(\n",
        "        results=db_results, max_hits=MAX_HITS.get(db_name))\n",
        "    if merged_msa.sequences and db_name != 'uniprot':\n",
        "      single_chain_msas.append(merged_msa)\n",
        "      msa_size = len(set(merged_msa.sequences))\n",
        "      print(f'{msa_size} unique sequences found in {db_name} for sequence {sequence_index}')\n",
        "    elif merged_msa.sequences and db_name == 'uniprot':\n",
        "      uniprot_msa = merged_msa\n",
        "\n",
        "  notebook_utils.show_msa_info(single_chain_msas=single_chain_msas, sequence_index=sequence_index)\n",
        "\n",
        "  # Turn the raw data into model features.\n",
        "  feature_dict = {}\n",
        "  feature_dict.update(pipeline.make_sequence_features(\n",
        "      sequence=sequence, description='query', num_res=len(sequence)))\n",
        "  feature_dict.update(pipeline.make_msa_features(msas=single_chain_msas))\n",
        "  # We don't use templates in AlphaFold Colab notebook, add only empty placeholder features.\n",
        "  feature_dict.update(notebook_utils.empty_placeholder_template_features(\n",
        "      num_templates=0, num_res=len(sequence)))\n",
        "\n",
        "  # Construct the all_seq features only for heteromers, not homomers.\n",
        "  if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
        "    valid_feats = msa_pairing.MSA_FEATURES + (\n",
        "        'msa_species_identifiers',\n",
        "    )\n",
        "    all_seq_features = {\n",
        "        f'{k}_all_seq': v for k, v in pipeline.make_msa_features([uniprot_msa]).items()\n",
        "        if k in valid_feats}\n",
        "    feature_dict.update(all_seq_features)\n",
        "\n",
        "  features_for_chain[protein.PDB_CHAIN_IDS[sequence_index - 1]] = feature_dict\n",
        "\n",
        "\n",
        "# Do further feature post-processing depending on the model type.\n",
        "if model_type_to_use == ModelType.MONOMER:\n",
        "  np_example = features_for_chain[protein.PDB_CHAIN_IDS[0]]\n",
        "\n",
        "elif model_type_to_use == ModelType.MULTIMER:\n",
        "  all_chain_features = {}\n",
        "  for chain_id, chain_features in features_for_chain.items():\n",
        "    all_chain_features[chain_id] = pipeline_multimer.convert_monomer_features(\n",
        "        chain_features, chain_id)\n",
        "\n",
        "  all_chain_features = pipeline_multimer.add_assembly_features(all_chain_features)\n",
        "\n",
        "  np_example = feature_processing.pair_and_merge(\n",
        "      all_chain_features=all_chain_features)\n",
        "\n",
        "  # Pad MSA to avoid zero-sized extra_msa.\n",
        "  np_example = pipeline_multimer.pad_msa(np_example, min_num_seq=512)\n",
        "\n",
        "executed_cells.add(4)"
      ],
      "metadata": {
        "id": "-KX5epyLCmxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Run AlphaFold and download prediction\n",
        "\n",
        "#@markdown Once this cell has been executed, a zip-archive with\n",
        "#@markdown the obtained prediction will be automatically downloaded\n",
        "#@markdown to your computer.\n",
        "\n",
        "#@markdown In case you are having issues with the relaxation stage, you can disable it below.\n",
        "#@markdown Warning: This means that the prediction might have distracting\n",
        "#@markdown small stereochemical violations.\n",
        "\n",
        "run_relax = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Relaxation is faster with a GPU, but we have found it to be less stable.\n",
        "#@markdown You may wish to enable GPU for higher performance, but if it doesn't\n",
        "#@markdown converge we suggested reverting to using without GPU.\n",
        "\n",
        "relax_use_gpu = False  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown The multimer model will continue recycling until the predictions stop\n",
        "#@markdown changing, up to the limit set here. For higher accuracy, at the\n",
        "#@markdown potential cost of longer inference times, set this to 20.\n",
        "\n",
        "multimer_model_max_num_recycles = 3  #@param {type:\"integer\"}\n",
        "\n",
        "# Track cell execution to ensure correct order\n",
        "notebook_utils.check_cell_execution_order(executed_cells, 5)\n",
        "\n",
        "# --- Run the model ---\n",
        "if model_type_to_use == ModelType.MONOMER:\n",
        "  model_names = config.MODEL_PRESETS['monomer'] + ('model_2_ptm',)\n",
        "elif model_type_to_use == ModelType.MULTIMER:\n",
        "  model_names = config.MODEL_PRESETS['multimer']\n",
        "\n",
        "output_dir = 'prediction'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "plddts = {}\n",
        "ranking_confidences = {}\n",
        "pae_outputs = {}\n",
        "unrelaxed_proteins = {}\n",
        "\n",
        "with tqdm.notebook.tqdm(total=len(model_names) + 1, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "  for model_name in model_names:\n",
        "    pbar.set_description(f'Running {model_name}')\n",
        "\n",
        "    cfg = config.model_config(model_name)\n",
        "\n",
        "    if model_type_to_use == ModelType.MONOMER:\n",
        "      cfg.data.eval.num_ensemble = 1\n",
        "    elif model_type_to_use == ModelType.MULTIMER:\n",
        "      cfg.model.num_ensemble_eval = 1\n",
        "\n",
        "    if model_type_to_use == ModelType.MULTIMER:\n",
        "      cfg.model.num_recycle = multimer_model_max_num_recycles\n",
        "      cfg.model.recycle_early_stop_tolerance = 0.5\n",
        "\n",
        "    params = data.get_model_haiku_params(model_name, './alphafold/data')\n",
        "    model_runner = model.RunModel(cfg, params)\n",
        "    processed_feature_dict = model_runner.process_features(np_example, random_seed=0)\n",
        "    prediction = model_runner.predict(processed_feature_dict, random_seed=random.randrange(sys.maxsize))\n",
        "\n",
        "    mean_plddt = prediction['plddt'].mean()\n",
        "\n",
        "    if model_type_to_use == ModelType.MONOMER:\n",
        "      if 'predicted_aligned_error' in prediction:\n",
        "        pae_outputs[model_name] = (prediction['predicted_aligned_error'],\n",
        "                                   prediction['max_predicted_aligned_error'])\n",
        "      else:\n",
        "        # Monomer models are sorted by mean pLDDT. Do not put monomer pTM models here as they\n",
        "        # should never get selected.\n",
        "        ranking_confidences[model_name] = prediction['ranking_confidence']\n",
        "        plddts[model_name] = prediction['plddt']\n",
        "    elif model_type_to_use == ModelType.MULTIMER:\n",
        "      # Multimer models are sorted by pTM+ipTM.\n",
        "      ranking_confidences[model_name] = prediction['ranking_confidence']\n",
        "      plddts[model_name] = prediction['plddt']\n",
        "      pae_outputs[model_name] = (prediction['predicted_aligned_error'],\n",
        "                                 prediction['max_predicted_aligned_error'])\n",
        "\n",
        "    # Set the b-factors to the per-residue plddt.\n",
        "    final_atom_mask = prediction['structure_module']['final_atom_mask']\n",
        "    b_factors = prediction['plddt'][:, None] * final_atom_mask\n",
        "    unrelaxed_protein = protein.from_prediction(\n",
        "        processed_feature_dict,\n",
        "        prediction,\n",
        "        b_factors=b_factors,\n",
        "        remove_leading_feature_dimension=(\n",
        "            model_type_to_use == ModelType.MONOMER))\n",
        "    unrelaxed_proteins[model_name] = unrelaxed_protein\n",
        "\n",
        "    # Delete unused outputs to save memory.\n",
        "    del model_runner\n",
        "    del params\n",
        "    del prediction\n",
        "    pbar.update(n=1)\n",
        "\n",
        "  # --- AMBER relax the best model ---\n",
        "\n",
        "  # Find the best model according to the mean pLDDT.\n",
        "  best_model_name = max(ranking_confidences.keys(), key=lambda x: ranking_confidences[x])\n",
        "\n",
        "  if run_relax:\n",
        "    pbar.set_description(f'AMBER relaxation')\n",
        "    amber_relaxer = relax.AmberRelaxation(\n",
        "        max_iterations=0,\n",
        "        tolerance=2.39,\n",
        "        stiffness=10.0,\n",
        "        exclude_residues=[],\n",
        "        max_outer_iterations=3,\n",
        "        use_gpu=relax_use_gpu)\n",
        "    relaxed_pdb, _, _ = amber_relaxer.process(prot=unrelaxed_proteins[best_model_name])\n",
        "  else:\n",
        "    print('Warning: Running without the relaxation stage.')\n",
        "    relaxed_pdb = protein.to_pdb(unrelaxed_proteins[best_model_name])\n",
        "  pbar.update(n=1)  # Finished AMBER relax.\n",
        "\n",
        "# Construct multiclass b-factors to indicate confidence bands\n",
        "# 0=very low, 1=low, 2=confident, 3=very high\n",
        "banded_b_factors = []\n",
        "for plddt in plddts[best_model_name]:\n",
        "  for idx, (min_val, max_val, _) in enumerate(PLDDT_BANDS):\n",
        "    if plddt >= min_val and plddt <= max_val:\n",
        "      banded_b_factors.append(idx)\n",
        "      break\n",
        "banded_b_factors = np.array(banded_b_factors)[:, None] * final_atom_mask\n",
        "to_visualize_pdb = utils.overwrite_b_factors(relaxed_pdb, banded_b_factors)\n",
        "\n",
        "\n",
        "# Write out the prediction\n",
        "pred_output_path = os.path.join(output_dir, 'selected_prediction.pdb')\n",
        "with open(pred_output_path, 'w') as f:\n",
        "  f.write(relaxed_pdb)\n",
        "\n",
        "\n",
        "# --- Visualise the prediction & confidence ---\n",
        "show_sidechains = True\n",
        "def plot_plddt_legend():\n",
        "  \"\"\"Plots the legend for pLDDT.\"\"\"\n",
        "  thresh = ['Very low (pLDDT < 50)',\n",
        "            'Low (70 > pLDDT > 50)',\n",
        "            'Confident (90 > pLDDT > 70)',\n",
        "            'Very high (pLDDT > 90)']\n",
        "\n",
        "  colors = [x[2] for x in PLDDT_BANDS]\n",
        "\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  for c in colors:\n",
        "    plt.bar(0, 0, color=c)\n",
        "  plt.legend(thresh, frameon=False, loc='center', fontsize=20)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  ax = plt.gca()\n",
        "  ax.spines['right'].set_visible(False)\n",
        "  ax.spines['top'].set_visible(False)\n",
        "  ax.spines['left'].set_visible(False)\n",
        "  ax.spines['bottom'].set_visible(False)\n",
        "  plt.title('Model Confidence', fontsize=20, pad=20)\n",
        "  return plt\n",
        "\n",
        "# Show the structure coloured by chain if the multimer model has been used.\n",
        "if model_type_to_use == ModelType.MULTIMER:\n",
        "  multichain_view = py3Dmol.view(width=800, height=600)\n",
        "  multichain_view.addModelsAsFrames(to_visualize_pdb)\n",
        "  multichain_style = {'cartoon': {'colorscheme': 'chain'}}\n",
        "  multichain_view.setStyle({'model': -1}, multichain_style)\n",
        "  multichain_view.zoomTo()\n",
        "  multichain_view.show()\n",
        "\n",
        "# Color the structure by per-residue pLDDT\n",
        "color_map = {i: bands[2] for i, bands in enumerate(PLDDT_BANDS)}\n",
        "view = py3Dmol.view(width=800, height=600)\n",
        "view.addModelsAsFrames(to_visualize_pdb)\n",
        "style = {'cartoon': {'colorscheme': {'prop': 'b', 'map': color_map}}}\n",
        "if show_sidechains:\n",
        "  style['stick'] = {}\n",
        "view.setStyle({'model': -1}, style)\n",
        "view.zoomTo()\n",
        "\n",
        "grid = GridspecLayout(1, 2)\n",
        "out = Output()\n",
        "with out:\n",
        "  view.show()\n",
        "grid[0, 0] = out\n",
        "\n",
        "out = Output()\n",
        "with out:\n",
        "  plot_plddt_legend().show()\n",
        "grid[0, 1] = out\n",
        "\n",
        "display.display(grid)\n",
        "\n",
        "# Display pLDDT and predicted aligned error (if output by the model).\n",
        "if pae_outputs:\n",
        "  num_plots = 2\n",
        "else:\n",
        "  num_plots = 1\n",
        "\n",
        "plt.figure(figsize=[8 * num_plots, 6])\n",
        "plt.subplot(1, num_plots, 1)\n",
        "plt.plot(plddts[best_model_name])\n",
        "plt.title('Predicted LDDT')\n",
        "plt.xlabel('Residue')\n",
        "plt.ylabel('pLDDT')\n",
        "\n",
        "if num_plots == 2:\n",
        "  plt.subplot(1, 2, 2)\n",
        "  pae, max_pae = list(pae_outputs.values())[0]\n",
        "  plt.imshow(pae, vmin=0., vmax=max_pae, cmap='Greens_r')\n",
        "  plt.colorbar(fraction=0.046, pad=0.04)\n",
        "\n",
        "  # Display lines at chain boundaries.\n",
        "  best_unrelaxed_prot = unrelaxed_proteins[best_model_name]\n",
        "  total_num_res = best_unrelaxed_prot.residue_index.shape[-1]\n",
        "  chain_ids = best_unrelaxed_prot.chain_index\n",
        "  for chain_boundary in np.nonzero(chain_ids[:-1] - chain_ids[1:]):\n",
        "    if chain_boundary.size:\n",
        "      plt.plot([0, total_num_res], [chain_boundary, chain_boundary], color='red')\n",
        "      plt.plot([chain_boundary, chain_boundary], [0, total_num_res], color='red')\n",
        "\n",
        "  plt.title('Predicted Aligned Error')\n",
        "  plt.xlabel('Scored residue')\n",
        "  plt.ylabel('Aligned residue')\n",
        "\n",
        "# Save the predicted aligned error (if it exists).\n",
        "pae_output_path = os.path.join(output_dir, 'predicted_aligned_error.json')\n",
        "if pae_outputs:\n",
        "  # Save predicted aligned error in the same format as the AF EMBL DB.\n",
        "  pae_data = confidence.pae_json(pae=pae, max_pae=max_pae.item())\n",
        "  with open(pae_output_path, 'w') as f:\n",
        "    f.write(pae_data)\n",
        "\n",
        "# --- Download the predictions ---\n",
        "shutil.make_archive(base_name='prediction', format='zip', root_dir=output_dir)\n",
        "files.download(f'{output_dir}.zip')\n",
        "\n",
        "executed_cells.add(5)"
      ],
      "metadata": {
        "id": "cXZav8ZQCpWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference List\n",
        "\n",
        "\n",
        "1.   Jumper, J., Evans, R., Pritzel, A. et al. Highly accurate protein structure prediction with AlphaFold. Nature 596, 583–589 (2021) (https://www.nature.com/articles/s41586-021-03819-2)\n",
        "2.   Wikimedia Foundation. (2023c, December 13). Alphafold. Wikipedia. https://en.wikipedia.org/wiki/AlphaFold\n",
        "3. YouTube. (2022). YouTube. Retrieved December 16, 2023, from https://www.youtube.com/watch?v=p1qjgkqwTdg&amp;ab_channel=HHMI%27sJaneliaResearchCampus.\n",
        "4. Dill, K. A., Ozkan, S. B., Shell, M. S., &amp; Weikl, T. R. (2008). The protein folding problem. Annual review of biophysics. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2443096/\n",
        "5. Wikimedia Foundation. (2023b, December 10). Attention (machine learning). Wikipedia. https://en.wikipedia.org/wiki/Attention_(machine_learning)\n",
        "6. Suri, Z. K. (2023, March 10). Convolution vs. attention. Curiosity. https://zshn25.github.io/CNNs-vs-Transformers/#:~:text=The%20basic%20idea%20of%20self,be%20the%20entire%20spatial%20locations.\n",
        "7. Wikimedia Foundation. (2023, September 13). Ablation (artificial intelligence). Wikipedia. https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence)\n",
        "8. Robin Pearce, Yang Zhang. Deep learning techniques have significantly impacted protein structure prediction and protein design. Current Opinion in Structural Biology, Volume 68 (2021) (https://doi.org/10.1016/j.sbi.2021.01.007)\n",
        "9. team, T. A., Moult, P. J., Ramakrishnan, P. V., &amp; Levinson, A. D. (2020, November 30). Alphafold: A solution to a 50-year-old Grand Challenge in Biology. Google DeepMind. https://deepmind.google/discover/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology/\n",
        "10. Wikimedia Foundation. (2022, November 21). Global distance test. Wikipedia. https://en.wikipedia.org/wiki/Global_distance_test"
      ],
      "metadata": {
        "id": "IMHrP6HixosM"
      }
    }
  ]
}